{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "height": 321,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2880,
     "status": "error",
     "timestamp": 1505781339378,
     "user": {
      "displayName": "Sara Robinson",
      "photoUrl": "//lh4.googleusercontent.com/-RR9n0dvbwgI/AAAAAAAAAAI/AAAAAAAAMYM/SOr5ZExpvXE/s50-c-k-no/photo.jpg",
      "userId": "112510032804989247452"
     },
     "user_tz": 240
    },
    "id": "783h64rGhA3T",
    "outputId": "d447b2ab-e321-4ee5-abd4-de2c0116302f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import helper\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,Conv1D,MaxPooling1D\n",
    "\n",
    "layers = keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters\n",
    "\n",
    "We'll set the hyperparameters for training our model. If you understand what they mean, feel free to play around - otherwise, we recommend keeping the defaults for your first run ðŸ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- We are using CPU now ----\n"
     ]
    }
   ],
   "source": [
    "# Hyperparams if GPU is available\n",
    "if tf.test.is_gpu_available():\n",
    "    print('---- We are using GPU now ----')\n",
    "    # GPU\n",
    "    BATCH_SIZE = 512  # Number of examples used in each iteration\n",
    "    EPOCHS = 80  # Number of passes through entire dataset\n",
    "    \n",
    "# Hyperparams for CPU training\n",
    "else:\n",
    "    print('---- We are using CPU now ----')\n",
    "    # CPU\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The wine reviews dataset is already attached to your workspace (if you want to attach your own data, [check out our docs](https://docs.floydhub.com/guides/workspace/#attaching-floydhub-datasets)).\n",
    "\n",
    "Let's take a look at data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X :(412038, 240, 1)\n",
      "Size of Y :(412038,)\n"
     ]
    }
   ],
   "source": [
    "data_path = '/floyd/input/gengduoshuju/'  # ADD path/to/dataset\n",
    "Y= pickle.load( open(os.path.join(data_path,'Y.pks'), \"rb\" ) )\n",
    "X= pickle.load( open(os.path.join(data_path,'X.pks'), \"rb\" ) )\n",
    "X = X.reshape((X.shape[0],X.shape[1],1))\n",
    "print(\"Size of X :\" + str(X.shape))\n",
    "print(\"Size of Y :\" + str(Y.shape))\n",
    "X = X.astype(np.float64)\n",
    "X = np.nan_to_num(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "331.0\n",
      "number of training examples = 403797\n",
      "number of test examples = 8241\n",
      "X_train shape: (403797, 240, 1)\n",
      "Y_train shape: (403797, 332)\n",
      "X_test shape: (8241, 240, 1)\n",
      "Y_test shape: (8241, 332)\n"
     ]
    }
   ],
   "source": [
    "X_train,  X_test, Y_train_orig,Y_test_orig= helper.divide_data(X,Y)\n",
    "print(Y.min())\n",
    "print(Y.max())\n",
    "num_classes = 332\n",
    "Y_train = keras.utils.to_categorical(Y_train_orig, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test_orig, num_classes)\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Tokens per sentence* plot (see above) is useful for setting the `MAX_LEN` training hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# Load the model what has already ben trained\n",
    "# ===================================================================================\n",
    "\n",
    "model = load_model(r\"floyd_model_xxl_data_ver7.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 240, 16)           80        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 240, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 120, 32)           2080      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 60, 64)            8256      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 60, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 30, 64)            16448     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 15, 32)            8224      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 332)               85324     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 332)               0         \n",
      "=================================================================\n",
      "Total params: 120,412\n",
      "Trainable params: 120,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 403797 samples, validate on 8241 samples\n",
      "Epoch 1/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1535 - acc: 0.9434 - val_loss: 0.1665 - val_acc: 0.9370\n",
      "Epoch 2/100\n",
      "403797/403797 [==============================] - 77s 190us/step - loss: 0.1530 - acc: 0.9434 - val_loss: 0.1582 - val_acc: 0.9396\n",
      "Epoch 3/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1543 - acc: 0.9430 - val_loss: 0.1735 - val_acc: 0.9350\n",
      "Epoch 4/100\n",
      "403797/403797 [==============================] - 77s 190us/step - loss: 0.1538 - acc: 0.9434 - val_loss: 0.1655 - val_acc: 0.9385\n",
      "Epoch 5/100\n",
      "403797/403797 [==============================] - 77s 190us/step - loss: 0.1577 - acc: 0.9438 - val_loss: 0.1506 - val_acc: 0.9431\n",
      "Epoch 6/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1488 - acc: 0.9455 - val_loss: 0.1785 - val_acc: 0.9353\n",
      "Epoch 7/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1554 - acc: 0.9428 - val_loss: 0.1803 - val_acc: 0.9335\n",
      "Epoch 8/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1552 - acc: 0.9431 - val_loss: 0.1660 - val_acc: 0.9376\n",
      "Epoch 9/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1524 - acc: 0.9435 - val_loss: 0.1625 - val_acc: 0.9379\n",
      "Epoch 10/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1503 - acc: 0.9444 - val_loss: 0.1891 - val_acc: 0.9282\n",
      "Epoch 11/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1531 - acc: 0.9436 - val_loss: 0.1810 - val_acc: 0.9336\n",
      "Epoch 12/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1500 - acc: 0.9446 - val_loss: 0.1602 - val_acc: 0.9420\n",
      "Epoch 13/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1541 - acc: 0.9434 - val_loss: 0.1804 - val_acc: 0.9362\n",
      "Epoch 14/100\n",
      "403797/403797 [==============================] - 77s 190us/step - loss: 0.1492 - acc: 0.9448 - val_loss: 0.1715 - val_acc: 0.9370\n",
      "Epoch 15/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1498 - acc: 0.9445 - val_loss: 0.2581 - val_acc: 0.9067\n",
      "Epoch 16/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1490 - acc: 0.9448 - val_loss: 0.1703 - val_acc: 0.9394\n",
      "Epoch 17/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1506 - acc: 0.9445 - val_loss: 0.1772 - val_acc: 0.9347\n",
      "Epoch 18/100\n",
      "403797/403797 [==============================] - 77s 190us/step - loss: 0.1474 - acc: 0.9455 - val_loss: 0.1699 - val_acc: 0.9401\n",
      "Epoch 19/100\n",
      "403797/403797 [==============================] - 77s 190us/step - loss: 0.1573 - acc: 0.9440 - val_loss: 0.1665 - val_acc: 0.9405\n",
      "Epoch 20/100\n",
      "403797/403797 [==============================] - 77s 190us/step - loss: 0.1453 - acc: 0.9464 - val_loss: 0.1542 - val_acc: 0.9433\n",
      "Epoch 21/100\n",
      "403797/403797 [==============================] - 77s 190us/step - loss: 0.1475 - acc: 0.9456 - val_loss: 0.1599 - val_acc: 0.9408\n",
      "Epoch 22/100\n",
      "403797/403797 [==============================] - 77s 190us/step - loss: 0.1491 - acc: 0.9450 - val_loss: 0.1635 - val_acc: 0.9399\n",
      "Epoch 23/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1445 - acc: 0.9465 - val_loss: 0.1665 - val_acc: 0.9391\n",
      "Epoch 24/100\n",
      "403797/403797 [==============================] - 76s 189us/step - loss: 0.1465 - acc: 0.9459 - val_loss: 0.1663 - val_acc: 0.9379\n",
      "Epoch 25/100\n",
      "403797/403797 [==============================] - 76s 189us/step - loss: 0.1473 - acc: 0.9460 - val_loss: 0.1579 - val_acc: 0.9424\n",
      "Epoch 26/100\n",
      "403797/403797 [==============================] - 76s 189us/step - loss: 0.1435 - acc: 0.9467 - val_loss: 0.1575 - val_acc: 0.9441\n",
      "Epoch 27/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1494 - acc: 0.9445 - val_loss: 0.1656 - val_acc: 0.9373\n",
      "Epoch 28/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1415 - acc: 0.9474 - val_loss: 0.1536 - val_acc: 0.9450\n",
      "Epoch 29/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1477 - acc: 0.9458 - val_loss: 0.1569 - val_acc: 0.9392\n",
      "Epoch 30/100\n",
      "403797/403797 [==============================] - 79s 197us/step - loss: 0.1437 - acc: 0.9466 - val_loss: 0.1651 - val_acc: 0.9378\n",
      "Epoch 31/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1432 - acc: 0.9470 - val_loss: 0.1792 - val_acc: 0.9333\n",
      "Epoch 32/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1455 - acc: 0.9463 - val_loss: 0.1592 - val_acc: 0.9416\n",
      "Epoch 33/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1438 - acc: 0.9464 - val_loss: 0.1614 - val_acc: 0.9402\n",
      "Epoch 34/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1434 - acc: 0.9468 - val_loss: 0.1772 - val_acc: 0.9334\n",
      "Epoch 35/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1440 - acc: 0.9464 - val_loss: 0.1967 - val_acc: 0.9299\n",
      "Epoch 36/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1442 - acc: 0.9466 - val_loss: 0.1692 - val_acc: 0.9350\n",
      "Epoch 37/100\n",
      "403797/403797 [==============================] - 80s 198us/step - loss: 0.1433 - acc: 0.9468 - val_loss: 0.1512 - val_acc: 0.9428\n",
      "Epoch 38/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1422 - acc: 0.9472 - val_loss: 0.1676 - val_acc: 0.9386\n",
      "Epoch 39/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1409 - acc: 0.9478 - val_loss: 0.1574 - val_acc: 0.9411\n",
      "Epoch 40/100\n",
      "403797/403797 [==============================] - 81s 200us/step - loss: 0.1438 - acc: 0.9466 - val_loss: 0.1522 - val_acc: 0.9426\n",
      "Epoch 41/100\n",
      "403797/403797 [==============================] - 80s 198us/step - loss: 0.1408 - acc: 0.9478 - val_loss: 0.1620 - val_acc: 0.9374\n",
      "Epoch 42/100\n",
      "403797/403797 [==============================] - 79s 196us/step - loss: 0.1395 - acc: 0.9483 - val_loss: 0.1638 - val_acc: 0.9424\n",
      "Epoch 43/100\n",
      "403797/403797 [==============================] - 79s 197us/step - loss: 0.1485 - acc: 0.9469 - val_loss: 0.1456 - val_acc: 0.9431\n",
      "Epoch 44/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1351 - acc: 0.9498 - val_loss: 0.1669 - val_acc: 0.9376\n",
      "Epoch 64/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1355 - acc: 0.9492 - val_loss: 0.1627 - val_acc: 0.9404\n",
      "Epoch 65/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1345 - acc: 0.9497 - val_loss: 0.1443 - val_acc: 0.9464\n",
      "Epoch 66/100\n",
      " 55296/403797 [===>..........................] - ETA: 1:07 - loss: 0.1285 - acc: 0.9514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1336 - acc: 0.9504 - val_loss: 0.1578 - val_acc: 0.9433\n",
      "Epoch 68/100\n",
      "403797/403797 [==============================] - 79s 196us/step - loss: 0.1352 - acc: 0.9497 - val_loss: 0.1650 - val_acc: 0.9405\n",
      "Epoch 69/100\n",
      "403797/403797 [==============================] - 79s 197us/step - loss: 0.1338 - acc: 0.9499 - val_loss: 0.1474 - val_acc: 0.9447\n",
      "Epoch 70/100\n",
      " 65024/403797 [===>..........................] - ETA: 1:05 - loss: 0.1288 - acc: 0.9516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1334 - acc: 0.9501 - val_loss: 0.1829 - val_acc: 0.9345\n",
      "Epoch 72/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1334 - acc: 0.9503 - val_loss: 0.1628 - val_acc: 0.9394\n",
      "Epoch 73/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1329 - acc: 0.9502 - val_loss: 0.1647 - val_acc: 0.9390\n",
      "Epoch 74/100\n",
      " 80640/403797 [====>.........................] - ETA: 1:02 - loss: 0.1376 - acc: 0.9485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 79s 197us/step - loss: 0.1340 - acc: 0.9500 - val_loss: 0.1645 - val_acc: 0.9387\n",
      "Epoch 77/100\n",
      "403797/403797 [==============================] - 79s 196us/step - loss: 0.1326 - acc: 0.9506 - val_loss: 0.1514 - val_acc: 0.9473\n",
      "Epoch 78/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1295 - acc: 0.9513 - val_loss: 0.1558 - val_acc: 0.9439\n",
      "Epoch 79/100\n",
      "145408/403797 [=========>....................] - ETA: 50s - loss: 0.1296 - acc: 0.9511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1334 - acc: 0.9506 - val_loss: 0.1474 - val_acc: 0.9483\n",
      "Epoch 81/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1279 - acc: 0.9522 - val_loss: 0.1746 - val_acc: 0.9371\n",
      "Epoch 82/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1306 - acc: 0.9511 - val_loss: 0.1524 - val_acc: 0.9447\n",
      "Epoch 83/100\n",
      "245248/403797 [=================>............] - ETA: 30s - loss: 0.1304 - acc: 0.9511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1317 - acc: 0.9511 - val_loss: 0.1501 - val_acc: 0.9471\n",
      "Epoch 85/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1335 - acc: 0.9498 - val_loss: 0.1396 - val_acc: 0.9487\n",
      "Epoch 86/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1301 - acc: 0.9515 - val_loss: 0.1516 - val_acc: 0.9467\n",
      "Epoch 87/100\n",
      "401920/403797 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1300 - acc: 0.9515 - val_loss: 0.2137 - val_acc: 0.9266\n",
      "Epoch 90/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1271 - acc: 0.9520 - val_loss: 0.1538 - val_acc: 0.9435\n",
      "Epoch 91/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1299 - acc: 0.9515 - val_loss: 0.1543 - val_acc: 0.9453\n",
      "Epoch 92/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1317 - acc: 0.9507 - val_loss: 0.1490 - val_acc: 0.9469\n",
      "Epoch 93/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1281 - acc: 0.9517 - val_loss: 0.1487 - val_acc: 0.9445\n",
      "Epoch 94/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1297 - acc: 0.9515 - val_loss: 0.1633 - val_acc: 0.9397\n",
      "Epoch 95/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1265 - acc: 0.9524 - val_loss: 0.1439 - val_acc: 0.9483\n",
      "Epoch 96/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1283 - acc: 0.9521 - val_loss: 0.1322 - val_acc: 0.9502\n",
      "Epoch 97/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1286 - acc: 0.9519 - val_loss: 0.1496 - val_acc: 0.9476\n",
      "Epoch 98/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1275 - acc: 0.9519 - val_loss: 0.1353 - val_acc: 0.9484\n",
      "Epoch 99/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1275 - acc: 0.9526 - val_loss: 0.1503 - val_acc: 0.9445\n",
      "Epoch 100/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1275 - acc: 0.9524 - val_loss: 0.1431 - val_acc: 0.9506\n",
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "model.save(r\"floyd_model_xxl_data_ver8.h5\")\n",
    "print('Training is done!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "keras-wide-deep.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
