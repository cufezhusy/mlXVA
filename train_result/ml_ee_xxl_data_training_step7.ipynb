{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "height": 321,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2880,
     "status": "error",
     "timestamp": 1505781339378,
     "user": {
      "displayName": "Sara Robinson",
      "photoUrl": "//lh4.googleusercontent.com/-RR9n0dvbwgI/AAAAAAAAAAI/AAAAAAAAMYM/SOr5ZExpvXE/s50-c-k-no/photo.jpg",
      "userId": "112510032804989247452"
     },
     "user_tz": 240
    },
    "id": "783h64rGhA3T",
    "outputId": "d447b2ab-e321-4ee5-abd4-de2c0116302f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import helper\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,Conv1D,MaxPooling1D\n",
    "\n",
    "layers = keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters\n",
    "\n",
    "We'll set the hyperparameters for training our model. If you understand what they mean, feel free to play around - otherwise, we recommend keeping the defaults for your first run ðŸ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- We are using CPU now ----\n"
     ]
    }
   ],
   "source": [
    "# Hyperparams if GPU is available\n",
    "if tf.test.is_gpu_available():\n",
    "    print('---- We are using GPU now ----')\n",
    "    # GPU\n",
    "    BATCH_SIZE = 512  # Number of examples used in each iteration\n",
    "    EPOCHS = 80  # Number of passes through entire dataset\n",
    "    \n",
    "# Hyperparams for CPU training\n",
    "else:\n",
    "    print('---- We are using CPU now ----')\n",
    "    # CPU\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The wine reviews dataset is already attached to your workspace (if you want to attach your own data, [check out our docs](https://docs.floydhub.com/guides/workspace/#attaching-floydhub-datasets)).\n",
    "\n",
    "Let's take a look at data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X :(412038, 240, 1)\n",
      "Size of Y :(412038,)\n"
     ]
    }
   ],
   "source": [
    "data_path = '/floyd/input/gengduoshuju/'  # ADD path/to/dataset\n",
    "Y= pickle.load( open(os.path.join(data_path,'Y.pks'), \"rb\" ) )\n",
    "X= pickle.load( open(os.path.join(data_path,'X.pks'), \"rb\" ) )\n",
    "X = X.reshape((X.shape[0],X.shape[1],1))\n",
    "print(\"Size of X :\" + str(X.shape))\n",
    "print(\"Size of Y :\" + str(Y.shape))\n",
    "X = X.astype(np.float64)\n",
    "X = np.nan_to_num(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "331.0\n",
      "number of training examples = 403797\n",
      "number of test examples = 8241\n",
      "X_train shape: (403797, 240, 1)\n",
      "Y_train shape: (403797, 332)\n",
      "X_test shape: (8241, 240, 1)\n",
      "Y_test shape: (8241, 332)\n"
     ]
    }
   ],
   "source": [
    "X_train,  X_test, Y_train_orig,Y_test_orig= helper.divide_data(X,Y)\n",
    "print(Y.min())\n",
    "print(Y.max())\n",
    "num_classes = 332\n",
    "Y_train = keras.utils.to_categorical(Y_train_orig, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test_orig, num_classes)\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Tokens per sentence* plot (see above) is useful for setting the `MAX_LEN` training hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# Load the model what has already ben trained\n",
    "# ===================================================================================\n",
    "\n",
    "model = load_model(r\"floyd_model_xxl_data_ver8.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 240, 16)           80        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 240, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 120, 32)           2080      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 60, 64)            8256      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 60, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 30, 64)            16448     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 15, 32)            8224      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 332)               85324     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 332)               0         \n",
      "=================================================================\n",
      "Total params: 120,412\n",
      "Trainable params: 120,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 403797 samples, validate on 8241 samples\n",
      "Epoch 1/100\n",
      "403797/403797 [==============================] - 80s 197us/step - loss: 0.1270 - acc: 0.9520 - val_loss: 0.1445 - val_acc: 0.9475\n",
      "Epoch 2/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1261 - acc: 0.9524 - val_loss: 0.1427 - val_acc: 0.9485\n",
      "Epoch 3/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1267 - acc: 0.9522 - val_loss: 0.1432 - val_acc: 0.9484\n",
      "Epoch 4/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1293 - acc: 0.9516 - val_loss: 0.1461 - val_acc: 0.9472\n",
      "Epoch 5/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1217 - acc: 0.9544 - val_loss: 0.1377 - val_acc: 0.9509\n",
      "Epoch 6/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1269 - acc: 0.9527 - val_loss: 0.1720 - val_acc: 0.9379\n",
      "Epoch 7/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1263 - acc: 0.9526 - val_loss: 0.1432 - val_acc: 0.9453\n",
      "Epoch 8/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1265 - acc: 0.9527 - val_loss: 0.1417 - val_acc: 0.9495\n",
      "Epoch 9/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1267 - acc: 0.9524 - val_loss: 0.1412 - val_acc: 0.9470\n",
      "Epoch 10/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1248 - acc: 0.9531 - val_loss: 0.1595 - val_acc: 0.9414\n",
      "Epoch 11/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1245 - acc: 0.9531 - val_loss: 0.1502 - val_acc: 0.9461\n",
      "Epoch 12/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1252 - acc: 0.9530 - val_loss: 0.1338 - val_acc: 0.9498\n",
      "Epoch 13/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1242 - acc: 0.9536 - val_loss: 0.1682 - val_acc: 0.9398\n",
      "Epoch 14/100\n",
      "403797/403797 [==============================] - 79s 196us/step - loss: 0.1249 - acc: 0.9532 - val_loss: 0.1441 - val_acc: 0.9488\n",
      "Epoch 15/100\n",
      "403797/403797 [==============================] - 79s 196us/step - loss: 0.1273 - acc: 0.9524 - val_loss: 0.1328 - val_acc: 0.9513\n",
      "Epoch 16/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1199 - acc: 0.9551 - val_loss: 0.1508 - val_acc: 0.9466\n",
      "Epoch 17/100\n",
      "403797/403797 [==============================] - 79s 197us/step - loss: 0.1234 - acc: 0.9538 - val_loss: 0.1425 - val_acc: 0.9469\n",
      "Epoch 18/100\n",
      "403797/403797 [==============================] - 79s 197us/step - loss: 0.1257 - acc: 0.9528 - val_loss: 0.1497 - val_acc: 0.9467\n",
      "Epoch 19/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1211 - acc: 0.9541 - val_loss: 0.1484 - val_acc: 0.9442\n",
      "Epoch 20/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1250 - acc: 0.9530 - val_loss: 0.1347 - val_acc: 0.9502\n",
      "Epoch 21/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1282 - acc: 0.9522 - val_loss: 0.1386 - val_acc: 0.9504\n",
      "Epoch 22/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1174 - acc: 0.9554 - val_loss: 0.1496 - val_acc: 0.9464\n",
      "Epoch 23/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1220 - acc: 0.9541 - val_loss: 0.1403 - val_acc: 0.9478\n",
      "Epoch 24/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1219 - acc: 0.9542 - val_loss: 0.1309 - val_acc: 0.9529\n",
      "Epoch 25/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1216 - acc: 0.9544 - val_loss: 0.1484 - val_acc: 0.9450\n",
      "Epoch 26/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1208 - acc: 0.9541 - val_loss: 0.1455 - val_acc: 0.9456\n",
      "Epoch 27/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1211 - acc: 0.9544 - val_loss: 0.1474 - val_acc: 0.9447\n",
      "Epoch 28/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1183 - acc: 0.9555 - val_loss: 0.1374 - val_acc: 0.9487\n",
      "Epoch 37/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1224 - acc: 0.9540 - val_loss: 0.1818 - val_acc: 0.9357\n",
      "Epoch 38/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1188 - acc: 0.9551 - val_loss: 0.1339 - val_acc: 0.9510\n",
      "Epoch 39/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1184 - acc: 0.9555 - val_loss: 0.1432 - val_acc: 0.9472\n",
      "Epoch 40/100\n",
      " 50688/403797 [==>...........................] - ETA: 1:08 - loss: 0.1228 - acc: 0.9541"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1184 - acc: 0.9554 - val_loss: 0.1324 - val_acc: 0.9524\n",
      "Epoch 42/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1186 - acc: 0.9551 - val_loss: 0.1436 - val_acc: 0.9478\n",
      "Epoch 43/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1190 - acc: 0.9549 - val_loss: 0.1307 - val_acc: 0.9518\n",
      "Epoch 44/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1227 - acc: 0.9540 - val_loss: 0.1423 - val_acc: 0.9462\n",
      "Epoch 45/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1142 - acc: 0.9566 - val_loss: 0.1299 - val_acc: 0.9515\n",
      "Epoch 46/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1188 - acc: 0.9551 - val_loss: 0.1576 - val_acc: 0.9438\n",
      "Epoch 47/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1194 - acc: 0.9549 - val_loss: 0.1348 - val_acc: 0.9487\n",
      "Epoch 48/100\n",
      " 79360/403797 [====>.........................] - ETA: 1:02 - loss: 0.1117 - acc: 0.9574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1195 - acc: 0.9548 - val_loss: 0.1408 - val_acc: 0.9475\n",
      "Epoch 50/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1161 - acc: 0.9560 - val_loss: 0.1402 - val_acc: 0.9466\n",
      "Epoch 51/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1192 - acc: 0.9550 - val_loss: 0.1541 - val_acc: 0.9466\n",
      "Epoch 52/100\n",
      "110080/403797 [=======>......................] - ETA: 56s - loss: 0.1148 - acc: 0.9570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1155 - acc: 0.9562 - val_loss: 0.1478 - val_acc: 0.9469\n",
      "Epoch 54/100\n",
      "403797/403797 [==============================] - 80s 197us/step - loss: 0.1150 - acc: 0.9563 - val_loss: 0.1285 - val_acc: 0.9518\n",
      "Epoch 55/100\n",
      "403797/403797 [==============================] - 79s 196us/step - loss: 0.1161 - acc: 0.9563 - val_loss: 0.1427 - val_acc: 0.9472\n",
      "Epoch 56/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1162 - acc: 0.9560 - val_loss: 0.1352 - val_acc: 0.9501\n",
      "Epoch 57/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1178 - acc: 0.9559 - val_loss: 0.1325 - val_acc: 0.9529\n",
      "Epoch 58/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1157 - acc: 0.9563 - val_loss: 0.1346 - val_acc: 0.9516\n",
      "Epoch 59/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1146 - acc: 0.9565 - val_loss: 0.1394 - val_acc: 0.9500\n",
      "Epoch 60/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1146 - acc: 0.9566 - val_loss: 0.1623 - val_acc: 0.9427\n",
      "Epoch 61/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1164 - acc: 0.9562 - val_loss: 0.1242 - val_acc: 0.9539\n",
      "Epoch 62/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1145 - acc: 0.9568 - val_loss: 0.1735 - val_acc: 0.9362\n",
      "Epoch 63/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1213 - acc: 0.9559 - val_loss: 0.1255 - val_acc: 0.9547\n",
      "Epoch 64/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1101 - acc: 0.9583 - val_loss: 0.1402 - val_acc: 0.9477\n",
      "Epoch 65/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1147 - acc: 0.9564 - val_loss: 0.1332 - val_acc: 0.9528\n",
      "Epoch 66/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1135 - acc: 0.9572 - val_loss: 0.1217 - val_acc: 0.9540\n",
      "Epoch 67/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1138 - acc: 0.9569 - val_loss: 0.1697 - val_acc: 0.9414\n",
      "Epoch 68/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1139 - acc: 0.9569 - val_loss: 0.1481 - val_acc: 0.9502\n",
      "Epoch 69/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1148 - acc: 0.9567 - val_loss: 0.1390 - val_acc: 0.9479\n",
      "Epoch 70/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1140 - acc: 0.9570 - val_loss: 0.1358 - val_acc: 0.9516\n",
      "Epoch 71/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1145 - acc: 0.9563 - val_loss: 0.1570 - val_acc: 0.9462\n",
      "Epoch 72/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1146 - acc: 0.9566 - val_loss: 0.1453 - val_acc: 0.9481\n",
      "Epoch 73/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1125 - acc: 0.9572 - val_loss: 0.1430 - val_acc: 0.9483\n",
      "Epoch 74/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1202 - acc: 0.9553 - val_loss: 0.1419 - val_acc: 0.9512\n",
      "Epoch 75/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1054 - acc: 0.9599 - val_loss: 0.1239 - val_acc: 0.9562\n",
      "Epoch 76/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1142 - acc: 0.9571 - val_loss: 0.1426 - val_acc: 0.9452\n",
      "Epoch 77/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1152 - acc: 0.9566 - val_loss: 0.1463 - val_acc: 0.9472\n",
      "Epoch 78/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1089 - acc: 0.9584 - val_loss: 0.1351 - val_acc: 0.9501\n",
      "Epoch 79/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1129 - acc: 0.9571 - val_loss: 0.1469 - val_acc: 0.9459\n",
      "Epoch 80/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1123 - acc: 0.9573 - val_loss: 0.1245 - val_acc: 0.9519\n",
      "Epoch 81/100\n",
      "403797/403797 [==============================] - 79s 195us/step - loss: 0.1150 - acc: 0.9567 - val_loss: 0.1385 - val_acc: 0.9504\n",
      "Epoch 82/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1085 - acc: 0.9590 - val_loss: 0.1341 - val_acc: 0.9512\n",
      "Epoch 83/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1112 - acc: 0.9577 - val_loss: 0.1290 - val_acc: 0.9513\n",
      "Epoch 84/100\n",
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1132 - acc: 0.9571 - val_loss: 0.1378 - val_acc: 0.9530\n",
      "Epoch 85/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1127 - acc: 0.9573 - val_loss: 0.1351 - val_acc: 0.9489\n",
      "Epoch 92/100\n",
      "403797/403797 [==============================] - 77s 191us/step - loss: 0.1105 - acc: 0.9581 - val_loss: 0.1423 - val_acc: 0.9504\n",
      "Epoch 93/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1103 - acc: 0.9580 - val_loss: 0.1399 - val_acc: 0.9454\n",
      "Epoch 94/100\n",
      "327168/403797 [=======================>......] - ETA: 14s - loss: 0.1091 - acc: 0.9588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1090 - acc: 0.9585 - val_loss: 0.1193 - val_acc: 0.9539\n",
      "Epoch 96/100\n",
      "403797/403797 [==============================] - 77s 192us/step - loss: 0.1134 - acc: 0.9572 - val_loss: 0.1101 - val_acc: 0.9592\n",
      "Epoch 97/100\n",
      "403797/403797 [==============================] - 78s 192us/step - loss: 0.1081 - acc: 0.9589 - val_loss: 0.1457 - val_acc: 0.9502\n",
      "Epoch 98/100\n",
      "403797/403797 [==============================] - 78s 193us/step - loss: 0.1097 - acc: 0.9580 - val_loss: 0.1245 - val_acc: 0.9530\n",
      "Epoch 99/100\n",
      " 67584/403797 [====>.........................] - ETA: 1:03 - loss: 0.1074 - acc: 0.9599"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 78s 194us/step - loss: 0.1090 - acc: 0.9586 - val_loss: 0.1239 - val_acc: 0.9547\n",
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "model.save(r\"floyd_model_xxl_data_ver9.h5\")\n",
    "print('Training is done!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "keras-wide-deep.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
