{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "height": 321.0,
     "output_extras": [
      {
       "item_id": 1.0
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2880.0,
     "status": "error",
     "timestamp": 1.505781339378E12,
     "user": {
      "displayName": "Sara Robinson",
      "photoUrl": "//lh4.googleusercontent.com/-RR9n0dvbwgI/AAAAAAAAAAI/AAAAAAAAMYM/SOr5ZExpvXE/s50-c-k-no/photo.jpg",
      "userId": "112510032804989247452"
     },
     "user_tz": 240.0
    },
    "id": "783h64rGhA3T",
    "outputId": "d447b2ab-e321-4ee5-abd4-de2c0116302f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import helper\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,Conv1D,MaxPooling1D\n",
    "\n",
    "layers = keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters\n",
    "\n",
    "We'll set the hyperparameters for training our model. If you understand what they mean, feel free to play around - otherwise, we recommend keeping the defaults for your first run ðŸ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- We are using CPU now ----\n"
     ]
    }
   ],
   "source": [
    "# Hyperparams if GPU is available\n",
    "if tf.test.is_gpu_available():\n",
    "    print('---- We are using GPU now ----')\n",
    "    # GPU\n",
    "    BATCH_SIZE = 512  # Number of examples used in each iteration\n",
    "    EPOCHS = 80  # Number of passes through entire dataset\n",
    "    \n",
    "# Hyperparams for CPU training\n",
    "else:\n",
    "    print('---- We are using CPU now ----')\n",
    "    # CPU\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The wine reviews dataset is already attached to your workspace (if you want to attach your own data, [check out our docs](https://docs.floydhub.com/guides/workspace/#attaching-floydhub-datasets)).\n",
    "\n",
    "Let's take a look at data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X :(412038, 240, 1)\n",
      "Size of Y :(412038,)\n"
     ]
    }
   ],
   "source": [
    "data_path = '/floyd/input/gengduoshuju/'  # ADD path/to/dataset\n",
    "Y= pickle.load( open(os.path.join(data_path,'Y.pks'), \"rb\" ) )\n",
    "X= pickle.load( open(os.path.join(data_path,'X.pks'), \"rb\" ) )\n",
    "X = X.reshape((X.shape[0],X.shape[1],1))\n",
    "print(\"Size of X :\" + str(X.shape))\n",
    "print(\"Size of Y :\" + str(Y.shape))\n",
    "X = X.astype(np.float64)\n",
    "X = np.nan_to_num(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "331.0\n",
      "number of training examples = 403797\n",
      "number of test examples = 8241\n",
      "X_train shape: (403797, 240, 1)\n",
      "Y_train shape: (403797, 332)\n",
      "X_test shape: (8241, 240, 1)\n",
      "Y_test shape: (8241, 332)\n"
     ]
    }
   ],
   "source": [
    "X_train,  X_test, Y_train_orig,Y_test_orig= helper.divide_data(X,Y)\n",
    "print(Y.min())\n",
    "print(Y.max())\n",
    "num_classes = 332\n",
    "Y_train = keras.utils.to_categorical(Y_train_orig, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test_orig, num_classes)\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Tokens per sentence* plot (see above) is useful for setting the `MAX_LEN` training hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# Load the model what has already ben trained\n",
    "# ===================================================================================\n",
    "\n",
    "model = load_model(r\"floyd_model_xxl_data_ver17.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 240, 16)           80        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 240, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 120, 32)           2080      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 60, 64)            8256      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 60, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 30, 64)            16448     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 15, 32)            8224      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 332)               85324     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 332)               0         \n",
      "=================================================================\n",
      "Total params: 120,412\n",
      "Trainable params: 120,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 403797 samples, validate on 8241 samples\n",
      "Epoch 1/100\n",
      "403797/403797 [==============================] - 86s 212us/step - loss: 0.0547 - acc: 0.9784 - val_loss: 0.0894 - val_acc: 0.9688\n",
      "Epoch 2/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0536 - acc: 0.9785 - val_loss: 0.0726 - val_acc: 0.9740\n",
      "Epoch 3/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0560 - acc: 0.9779 - val_loss: 0.0731 - val_acc: 0.9738\n",
      "Epoch 4/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0525 - acc: 0.9793 - val_loss: 0.0732 - val_acc: 0.9731\n",
      "Epoch 5/100\n",
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0548 - acc: 0.9783 - val_loss: 0.0760 - val_acc: 0.9734\n",
      "Epoch 6/100\n",
      "403797/403797 [==============================] - 82s 204us/step - loss: 0.0542 - acc: 0.9786 - val_loss: 0.0728 - val_acc: 0.9752\n",
      "Epoch 7/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0548 - acc: 0.9783 - val_loss: 0.0739 - val_acc: 0.9745\n",
      "Epoch 8/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0542 - acc: 0.9786 - val_loss: 0.0805 - val_acc: 0.9712\n",
      "Epoch 9/100\n",
      "403797/403797 [==============================] - 81s 202us/step - loss: 0.0534 - acc: 0.9788 - val_loss: 0.0809 - val_acc: 0.9705\n",
      "Epoch 10/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0534 - acc: 0.9788 - val_loss: 0.0720 - val_acc: 0.9738\n",
      "Epoch 11/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0537 - acc: 0.9787 - val_loss: 0.0795 - val_acc: 0.9717\n",
      "Epoch 12/100\n",
      "403797/403797 [==============================] - 81s 202us/step - loss: 0.0555 - acc: 0.9781 - val_loss: 0.0899 - val_acc: 0.9674\n",
      "Epoch 13/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0534 - acc: 0.9789 - val_loss: 0.0837 - val_acc: 0.9703\n",
      "Epoch 14/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0549 - acc: 0.9782 - val_loss: 0.0722 - val_acc: 0.9721\n",
      "Epoch 15/100\n",
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0535 - acc: 0.9787 - val_loss: 0.0723 - val_acc: 0.9738\n",
      "Epoch 16/100\n",
      "403797/403797 [==============================] - 82s 204us/step - loss: 0.0557 - acc: 0.9779 - val_loss: 0.0944 - val_acc: 0.9669\n",
      "Epoch 17/100\n",
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0520 - acc: 0.9791 - val_loss: 0.0837 - val_acc: 0.9721\n",
      "Epoch 18/100\n",
      "403797/403797 [==============================] - 81s 199us/step - loss: 0.0533 - acc: 0.9788 - val_loss: 0.0720 - val_acc: 0.9739\n",
      "Epoch 19/100\n",
      "403797/403797 [==============================] - 80s 199us/step - loss: 0.0538 - acc: 0.9787 - val_loss: 0.0796 - val_acc: 0.9706\n",
      "Epoch 20/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0534 - acc: 0.9790 - val_loss: 0.0806 - val_acc: 0.9725\n",
      "Epoch 21/100\n",
      "403797/403797 [==============================] - 80s 199us/step - loss: 0.0537 - acc: 0.9789 - val_loss: 0.0842 - val_acc: 0.9685\n",
      "Epoch 22/100\n",
      "403797/403797 [==============================] - 81s 202us/step - loss: 0.0542 - acc: 0.9786 - val_loss: 0.0836 - val_acc: 0.9686\n",
      "Epoch 33/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0529 - acc: 0.9791 - val_loss: 0.0747 - val_acc: 0.9746\n",
      "Epoch 34/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0526 - acc: 0.9793 - val_loss: 0.0825 - val_acc: 0.9695\n",
      "Epoch 35/100\n",
      "131840/403797 [========>.....................] - ETA: 54s - loss: 0.0505 - acc: 0.9800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0526 - acc: 0.9791 - val_loss: 0.0874 - val_acc: 0.9711\n",
      "Epoch 37/100\n",
      "403797/403797 [==============================] - 81s 200us/step - loss: 0.0524 - acc: 0.9792 - val_loss: 0.0747 - val_acc: 0.9725\n",
      "Epoch 38/100\n",
      "217088/403797 [===============>..............] - ETA: 37s - loss: 0.0537 - acc: 0.9789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0539 - acc: 0.9788 - val_loss: 0.0858 - val_acc: 0.9697\n",
      "Epoch 40/100\n",
      "403797/403797 [==============================] - 81s 200us/step - loss: 0.0527 - acc: 0.9790 - val_loss: 0.0658 - val_acc: 0.9738\n",
      "Epoch 41/100\n",
      "403797/403797 [==============================] - 81s 202us/step - loss: 0.0515 - acc: 0.9796 - val_loss: 0.0865 - val_acc: 0.9709\n",
      "Epoch 42/100\n",
      " 80896/403797 [=====>........................] - ETA: 1:04 - loss: 0.0541 - acc: 0.9787"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0542 - acc: 0.9786 - val_loss: 0.0835 - val_acc: 0.9697\n",
      "Epoch 43/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0527 - acc: 0.9791 - val_loss: 0.0830 - val_acc: 0.9686\n",
      "Epoch 44/100\n",
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0524 - acc: 0.9790 - val_loss: 0.0851 - val_acc: 0.9687\n",
      "Epoch 45/100\n",
      " 80896/403797 [=====>........................] - ETA: 1:04 - loss: 0.0560 - acc: 0.9781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0527 - acc: 0.9792 - val_loss: 0.0841 - val_acc: 0.9697\n",
      "Epoch 46/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0533 - acc: 0.9792 - val_loss: 0.0857 - val_acc: 0.9687\n",
      "Epoch 47/100\n",
      "403797/403797 [==============================] - 81s 200us/step - loss: 0.0518 - acc: 0.9793 - val_loss: 0.0932 - val_acc: 0.9671\n",
      "Epoch 49/100\n",
      "403797/403797 [==============================] - 81s 200us/step - loss: 0.0527 - acc: 0.9790 - val_loss: 0.0791 - val_acc: 0.9714\n",
      "Epoch 50/100\n",
      "289536/403797 [====================>.........] - ETA: 22s - loss: 0.0504 - acc: 0.9801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0530 - acc: 0.9791 - val_loss: 0.0800 - val_acc: 0.9699\n",
      "Epoch 52/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0530 - acc: 0.9793 - val_loss: 0.0711 - val_acc: 0.9734\n",
      "Epoch 53/100\n",
      "297472/403797 [=====================>........] - ETA: 21s - loss: 0.0514 - acc: 0.9796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0532 - acc: 0.9787 - val_loss: 0.0807 - val_acc: 0.9735\n",
      "Epoch 55/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0522 - acc: 0.9793 - val_loss: 0.0848 - val_acc: 0.9687\n",
      "Epoch 56/100\n",
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0523 - acc: 0.9792 - val_loss: 0.0736 - val_acc: 0.9740\n",
      "Epoch 57/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0525 - acc: 0.9792 - val_loss: 0.0767 - val_acc: 0.9711\n",
      "Epoch 58/100\n",
      " 48896/403797 [==>...........................] - ETA: 1:11 - loss: 0.0557 - acc: 0.9782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0524 - acc: 0.9793 - val_loss: 0.0752 - val_acc: 0.9737\n",
      "Epoch 59/100\n",
      "403797/403797 [==============================] - 81s 202us/step - loss: 0.0532 - acc: 0.9791 - val_loss: 0.0854 - val_acc: 0.9698\n",
      "Epoch 61/100\n",
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0519 - acc: 0.9795 - val_loss: 0.0762 - val_acc: 0.9734\n",
      "Epoch 62/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0530 - acc: 0.9791 - val_loss: 0.0745 - val_acc: 0.9721\n",
      "Epoch 63/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0512 - acc: 0.9796 - val_loss: 0.0767 - val_acc: 0.9723\n",
      "Epoch 64/100\n",
      "403797/403797 [==============================] - 82s 204us/step - loss: 0.0535 - acc: 0.9788 - val_loss: 0.0820 - val_acc: 0.9705\n",
      "Epoch 65/100\n",
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0535 - acc: 0.9788 - val_loss: 0.0691 - val_acc: 0.9749\n",
      "Epoch 66/100\n",
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0498 - acc: 0.9801 - val_loss: 0.0618 - val_acc: 0.9767\n",
      "Epoch 67/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0517 - acc: 0.9796 - val_loss: 0.0745 - val_acc: 0.9739\n",
      "Epoch 68/100\n",
      "403797/403797 [==============================] - 81s 201us/step - loss: 0.0513 - acc: 0.9799 - val_loss: 0.0920 - val_acc: 0.9686\n",
      "Epoch 69/100\n",
      "403797/403797 [==============================] - 81s 200us/step - loss: 0.0511 - acc: 0.9796 - val_loss: 0.0668 - val_acc: 0.9752\n",
      "Epoch 70/100\n",
      "403797/403797 [==============================] - 82s 202us/step - loss: 0.0513 - acc: 0.9797 - val_loss: 0.0706 - val_acc: 0.9740\n",
      "Epoch 71/100\n",
      "403797/403797 [==============================] - 80s 198us/step - loss: 0.0529 - acc: 0.9789 - val_loss: 0.0987 - val_acc: 0.9638\n",
      "Epoch 72/100\n",
      "403797/403797 [==============================] - 80s 199us/step - loss: 0.0523 - acc: 0.9790 - val_loss: 0.0780 - val_acc: 0.9722\n",
      "Epoch 73/100\n",
      "403797/403797 [==============================] - 80s 197us/step - loss: 0.0519 - acc: 0.9794 - val_loss: 0.0727 - val_acc: 0.9732\n",
      "Epoch 74/100\n",
      "403797/403797 [==============================] - 80s 197us/step - loss: 0.0533 - acc: 0.9789 - val_loss: 0.0870 - val_acc: 0.9680\n",
      "Epoch 75/100\n",
      "403797/403797 [==============================] - 80s 198us/step - loss: 0.0510 - acc: 0.9797 - val_loss: 0.0761 - val_acc: 0.9709\n",
      "Epoch 76/100\n",
      "403797/403797 [==============================] - 82s 203us/step - loss: 0.0517 - acc: 0.9794 - val_loss: 0.0961 - val_acc: 0.9654\n",
      "Epoch 77/100\n",
      "403797/403797 [==============================] - 84s 209us/step - loss: 0.0515 - acc: 0.9794 - val_loss: 0.0726 - val_acc: 0.9735\n",
      "Epoch 78/100\n",
      "403797/403797 [==============================] - 84s 208us/step - loss: 0.0518 - acc: 0.9794 - val_loss: 0.0900 - val_acc: 0.9674\n",
      "Epoch 79/100\n",
      "403797/403797 [==============================] - 83s 205us/step - loss: 0.0524 - acc: 0.9794 - val_loss: 0.0777 - val_acc: 0.9709\n",
      "Epoch 80/100\n",
      " 28928/403797 [=>............................] - ETA: 1:14 - loss: 0.0482 - acc: 0.9808"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "model.save(r\"floyd_model_xxl_data_ver18.h5\")\n",
    "print('Training is done!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "keras-wide-deep.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
